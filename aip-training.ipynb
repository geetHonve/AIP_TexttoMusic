{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# cloning the musiclm-pytorch github repository\n!git clone https://github.com/lucidrains/musiclm-pytorch.git","metadata":{"execution":{"iopub.status.busy":"2023-05-21T09:49:17.182844Z","iopub.execute_input":"2023-05-21T09:49:17.183176Z","iopub.status.idle":"2023-05-21T09:49:18.120473Z","shell.execute_reply.started":"2023-05-21T09:49:17.183149Z","shell.execute_reply":"2023-05-21T09:49:18.119454Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'musiclm-pytorch'...\nremote: Enumerating objects: 293, done.\u001b[K\nremote: Counting objects: 100% (137/137), done.\u001b[K\nremote: Compressing objects: 100% (35/35), done.\u001b[K\nremote: Total 293 (delta 129), reused 105 (delta 102), pack-reused 156\u001b[K\nReceiving objects: 100% (293/293), 193.50 KiB | 11.38 MiB/s, done.\nResolving deltas: 100% (180/180), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install beartype\n!pip install lion_pytorch\n!pip install einops","metadata":{"execution":{"iopub.status.busy":"2023-05-21T09:51:01.949153Z","iopub.execute_input":"2023-05-21T09:51:01.949514Z","iopub.status.idle":"2023-05-21T09:51:30.910105Z","shell.execute_reply.started":"2023-05-21T09:51:01.949482Z","shell.execute_reply":"2023-05-21T09:51:30.908809Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting beartype\n  Downloading beartype-0.14.0-py3-none-any.whl (720 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.2/720.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: beartype\nSuccessfully installed beartype-0.14.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting lion_pytorch\n  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from lion_pytorch) (2.0.0+cpu)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion_pytorch) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion_pytorch) (3.11.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion_pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion_pytorch) (1.11.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->lion_pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->lion_pytorch) (1.3.0)\nInstalling collected packages: lion_pytorch\nSuccessfully installed lion_pytorch-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.6.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install audiolm_pytorch\n!pip install x_clip\n!pip install musiclm_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-05-21T09:51:44.580635Z","iopub.execute_input":"2023-05-21T09:51:44.580978Z","iopub.status.idle":"2023-05-21T09:52:56.422793Z","shell.execute_reply.started":"2023-05-21T09:51:44.580951Z","shell.execute_reply":"2023-05-21T09:52:56.421709Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting audiolm_pytorch\n  Downloading audiolm_pytorch-1.0.4-py3-none-any.whl (37 kB)\nCollecting ema-pytorch>=0.2.2\n  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.2.0)\nRequirement already satisfied: lion-pytorch in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.1.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (2.0.1+cpu)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (4.28.1)\nRequirement already satisfied: einops>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.6.1)\nCollecting encodec\n  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.2.2)\nRequirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (2.0.0+cpu)\nCollecting vector-quantize-pytorch>=1.4.1\n  Downloading vector_quantize_pytorch-1.5.3-py3-none-any.whl (11 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.12.0)\nCollecting local-attention>=1.8.4\n  Downloading local_attention-1.8.6-py3-none-any.whl (8.1 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (4.64.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.1.98)\nCollecting fairseq\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beartype in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.14.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (1.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.11.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->audiolm_pytorch) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->audiolm_pytorch) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate->audiolm_pytorch) (1.23.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->audiolm_pytorch) (5.9.4)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (1.15.1)\nCollecting bitarray\n  Downloading bitarray-2.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.7/272.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (0.29.34)\nCollecting omegaconf<2.1\n  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nCollecting hydra-core<1.1,>=1.0.7\n  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sacrebleu>=1.4.12\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (2023.3.23)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm_pytorch) (1.9.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm_pytorch) (3.1.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (2.28.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (0.13.4)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (0.13.3)\nCollecting antlr4-python3-runtime==4.8\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate->audiolm_pytorch) (3.0.9)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.9.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (4.9.2)\nCollecting portalocker\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.4.6)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->audiolm_pytorch) (2.21)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->audiolm_pytorch) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (2022.12.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->audiolm_pytorch) (1.3.0)\nBuilding wheels for collected packages: encodec, fairseq, antlr4-python3-runtime\n  Building wheel for encodec (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45779 sha256=6640fd0de2cc624dbb683938d62a45d0ed763f389927a9af25c811d92711edda\n  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10390496 sha256=4d73b2b93b887126c85aded3c8c86dea81437181c7cd3a96788c59a9f41bd62e\n  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=b316564ade17032bf35f63c98839ad3d2c26f4e6ca145ba84cb8afe6a2559629\n  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built encodec fairseq antlr4-python3-runtime\nInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, vector-quantize-pytorch, local-attention, ema-pytorch, fairseq, encodec, audiolm_pytorch\nSuccessfully installed antlr4-python3-runtime-4.8 audiolm_pytorch-1.0.4 bitarray-2.7.3 ema-pytorch-0.2.3 encodec-0.1.1 fairseq-0.12.2 hydra-core-1.0.7 local-attention-1.8.6 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 vector-quantize-pytorch-1.5.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting x_clip\n  Downloading x_clip-0.12.1-py3-none-any.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting ftfy\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from x_clip) (0.15.1+cpu)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from x_clip) (2023.3.23)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from x_clip) (2.0.0+cpu)\nRequirement already satisfied: einops>=0.3 in /opt/conda/lib/python3.10/site-packages (from x_clip) (0.6.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->x_clip) (3.11.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->x_clip) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->x_clip) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->x_clip) (3.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->x_clip) (4.5.0)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->x_clip) (0.2.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->x_clip) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->x_clip) (9.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->x_clip) (1.23.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->x_clip) (2.1.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x_clip) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x_clip) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x_clip) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x_clip) (2.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->x_clip) (1.3.0)\nInstalling collected packages: ftfy, x_clip\nSuccessfully installed ftfy-6.1.1 x_clip-0.12.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting musiclm_pytorch\n  Downloading musiclm_pytorch-0.2.2-py3-none-any.whl (12 kB)\nRequirement already satisfied: audiolm-pytorch>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (1.0.4)\nRequirement already satisfied: vector-quantize-pytorch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (1.5.3)\nRequirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (2.0.0+cpu)\nRequirement already satisfied: x-clip in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (0.12.1)\nRequirement already satisfied: beartype in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (0.14.0)\nRequirement already satisfied: einops>=0.6 in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (0.6.1)\nRequirement already satisfied: lion-pytorch in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (0.1.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (2.0.1+cpu)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from musiclm_pytorch) (0.12.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.1.98)\nRequirement already satisfied: local-attention>=1.8.4 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.8.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (4.64.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (4.28.1)\nRequirement already satisfied: ema-pytorch>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.2.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.2.0)\nRequirement already satisfied: encodec in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.1.1)\nRequirement already satisfied: fairseq in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.12.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm_pytorch) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm_pytorch) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm_pytorch) (3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm_pytorch) (1.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm_pytorch) (3.11.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm_pytorch) (1.23.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm_pytorch) (6.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm_pytorch) (5.9.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm_pytorch) (21.3)\nRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm_pytorch) (6.1.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm_pytorch) (0.15.1+cpu)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm_pytorch) (2023.3.23)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate->musiclm_pytorch) (3.0.9)\nRequirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (2.3.1)\nRequirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (2.7.3)\nRequirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.0.7)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.15.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.29.34)\nRequirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (2.0.6)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->x-clip->musiclm_pytorch) (0.2.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->musiclm_pytorch) (2.1.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm_pytorch) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm_pytorch) (1.9.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->musiclm_pytorch) (1.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->x-clip->musiclm_pytorch) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->x-clip->musiclm_pytorch) (9.5.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.13.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.13.4)\nRequirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (4.8)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.4.6)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (0.9.0)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (2.7.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (4.9.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->audiolm-pytorch>=0.17.0->musiclm_pytorch) (2.21)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x-clip->musiclm_pytorch) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x-clip->musiclm_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x-clip->musiclm_pytorch) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->x-clip->musiclm_pytorch) (2.1.1)\nInstalling collected packages: musiclm_pytorch\nSuccessfully installed musiclm_pytorch-0.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n\naudio_transformer = AudioSpectrogramTransformer(\n    dim = 512,\n    depth = 6,\n    heads = 8,\n    dim_head = 64,\n    spec_n_fft = 128,\n    spec_win_length = 24,\n    spec_aug_stretch_factor = 0.8\n)\n\ntext_transformer = TextTransformer(\n    dim = 512,\n    depth = 6,\n    heads = 8,\n    dim_head = 64\n)\n\nmulan = MuLaN(\n    audio_transformer = audio_transformer,\n    text_transformer = text_transformer\n)\n\n# get a ton of <sound, text> pairs and train\n\nwavs = torch.randn(2, 1024)\ntexts = torch.randint(0, 20000, (2, 256))\n\nloss = mulan(wavs, texts)\nloss.backward()\n\n# after much training, you can embed sounds and text into a joint embedding space\n# for conditioning the audio LM\n\nembeds = mulan.get_audio_latents(wavs)  # during training\n\nembeds = mulan.get_text_latents(texts)  # during inference","metadata":{"execution":{"iopub.status.busy":"2023-05-21T09:53:30.622621Z","iopub.execute_input":"2023-05-21T09:53:30.623017Z","iopub.status.idle":"2023-05-21T09:53:47.429458Z","shell.execute_reply.started":"2023-05-21T09:53:30.622985Z","shell.execute_reply":"2023-05-21T09:53:47.428586Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"spectrogram yielded shape of (65, 86), but had to be cropped to (64, 80) to be patchified for transformer\n","output_type":"stream"}]},{"cell_type":"code","source":"from musiclm_pytorch import MuLaNEmbedQuantizer\n\n# setup the quantizer with the namespaced conditioning embeddings, unique per quantizer as well as namespace (per transformer)\n\nquantizer = MuLaNEmbedQuantizer(\n    mulan = mulan,                          # pass in trained mulan from above\n    conditioning_dims = (1024, 1024, 1024), # say all three transformers have model dimensions of 1024\n    namespaces = ('semantic', 'coarse', 'fine')\n)\n\n# now say you want the conditioning embeddings for semantic transformer\n\nwavs = torch.randn(2, 1024)\nconds = quantizer(wavs = wavs, namespace = 'semantic') # (2, 8, 1024) - 8 is number of quantizers","metadata":{"execution":{"iopub.status.busy":"2023-05-21T09:55:02.495597Z","iopub.execute_input":"2023-05-21T09:55:02.495943Z","iopub.status.idle":"2023-05-21T09:55:02.905877Z","shell.execute_reply.started":"2023-05-21T09:55:02.495917Z","shell.execute_reply":"2023-05-21T09:55:02.905131Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:07:08.462141Z","iopub.execute_input":"2023-05-21T10:07:08.462519Z","iopub.status.idle":"2023-05-21T10:07:17.477022Z","shell.execute_reply.started":"2023-05-21T10:07:08.462489Z","shell.execute_reply":"2023-05-21T10:07:17.475579Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\nRequirement already satisfied: torch==1.11.0+cu113 in /opt/conda/lib/python3.10/site-packages (1.11.0+cu113)\nRequirement already satisfied: torchvision==0.12.0+cu113 in /opt/conda/lib/python3.10/site-packages (0.12.0+cu113)\nRequirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.10/site-packages (0.11.0+cu113)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.11.0+cu113) (4.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cu113) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cu113) (9.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cu113) (1.23.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cu113) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cu113) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cu113) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cu113) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import nn\nnet = nn.Sequential(\n    nn.Linear(18*18, 80),\n    nn.ReLU(),\n    nn.Linear(80, 80),\n    nn.ReLU(),\n    nn.Linear(80, 10),\n    nn.LogSoftmax()\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:06:40.214814Z","iopub.execute_input":"2023-05-21T10:06:40.215233Z","iopub.status.idle":"2023-05-21T10:06:40.223664Z","shell.execute_reply.started":"2023-05-21T10:06:40.215203Z","shell.execute_reply":"2023-05-21T10:06:40.222052Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n\nwav2vec = HubertWithKmeans(\n    checkpoint_path = '/kaggle/input/somethingsomethign/hubert_base_ls960.pt',\n    kmeans_path = '/kaggle/input/somethingpart2/hubert_base_ls960_L9_km500.bin'\n)\n\nsemantic_transformer = SemanticTransformer(\n    num_semantic_tokens = wav2vec.codebook_size,\n    dim = 1024,\n    depth = 6,\n    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n).cuda()\n\ntrainer = SemanticTransformerTrainer(\n    transformer = semantic_transformer,\n    wav2vec = wav2vec,\n    audio_conditioner = quantizer,   # pass in the MulanEmbedQuantizer instance above\n    folder ='/kaggle/input/midi-files',\n    batch_size = 1,\n    data_max_length = 320 * 32,\n    num_train_steps = 1\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T10:07:24.282937Z","iopub.execute_input":"2023-05-21T10:07:24.283305Z","iopub.status.idle":"2023-05-21T10:07:31.333023Z","shell.execute_reply.started":"2023-05-21T10:07:24.283275Z","shell.execute_reply":"2023-05-21T10:07:31.331881Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudiolm_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n\u001b[1;32m      4\u001b[0m wav2vec \u001b[38;5;241m=\u001b[39m HubertWithKmeans(\n\u001b[1;32m      5\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/somethingsomethign/hubert_base_ls960.pt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     kmeans_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/somethingpart2/hubert_base_ls960_L9_km500.bin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m semantic_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mSemanticTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_semantic_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwav2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodebook_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_text_condition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# this must be set to True (same for CoarseTransformer and FineTransformers)\u001b[39;49;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SemanticTransformerTrainer(\n\u001b[1;32m     17\u001b[0m     transformer \u001b[38;5;241m=\u001b[39m semantic_transformer,\n\u001b[1;32m     18\u001b[0m     wav2vec \u001b[38;5;241m=\u001b[39m wav2vec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     num_train_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"],"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error"}]}]}